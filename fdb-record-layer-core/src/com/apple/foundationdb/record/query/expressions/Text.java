/*
 * Text.java
 *
 * This source file is part of the FoundationDB open source project
 *
 * Copyright 2015-2018 Apple Inc. and the FoundationDB project authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.apple.foundationdb.record.query.expressions;

import com.apple.foundationdb.record.provider.common.text.DefaultTextTokenizer;

import javax.annotation.Nonnull;
import javax.annotation.Nullable;
import java.util.Collections;
import java.util.List;

/**
 * Predicates that can be applied to a field that has been indexed with a full-text index. These
 * allow for querying on properties of the text contents, e.g., whether the text contains a
 * given token, token list, or phrase. Most of the methods here that allow for multiple
 * tokens to be supplied can either be given a single string or a list. If a single string is
 * given, then the string will be tokenized later using an appropriate tokenizer. If a list
 * is given, then the assumption is that the user has already tokenized the string and the
 * list is the result of that tokenization.
 *
 * <p>
 * This type allows the user to specify a "tokenizer name". If one is given, then it will use
 * this tokenizer to tokenize the query string (if not pre-tokenized) and will require that
 * if an index is used, it uses the tokenizer provided. If no tokenizer is specified, then
 * it will allow itself to be matched against any text index on the field and apply the
 * index's tokenizer to the query string. If no suitable index can be found and a full
 * scan with a post-filter has to be done, then a fallback tokenizer will be used both to
 * tokenize the query string as well as to tokenize the record's text. By default, this
 * is the {@link DefaultTextTokenizer} (with name "{@value DefaultTextTokenizer#NAME}"), but
 * one can specify a different one if one wishes.
 * </p>
 *
 * <p>
 * This should be created by calling the {@link Field#text() text()} method on a query
 * {@link Field} or {@link OneOfThem} instance. For example, one might call: <code>Query.field("text").text()</code>
 * to create a predicate on the <code>text</code> field's contents.
 * </p>
 *
 * <!-- TODO: When the planner can support this, we can remove this warning.-->
 * <p>
 * <b>Warning:</b> the query planner does not currently support evaluating text
 * predicates by scanning the appropriate indexes, so any text predicate will
 * almost certainly end up scanning the record store and searching every record.
 * Planner support is in development, but this predicate type should probably not
 * be used in production until that has been completed.
 * </p>
 *
 * @see com.apple.foundationdb.record.provider.foundationdb.indexes.TextIndexMaintainer TextIndexMaintainer
 * @see com.apple.foundationdb.record.provider.common.text.TextTokenizer TextTokenizer
 * @see DefaultTextTokenizer
 */
public abstract class Text {
    @Nullable
    private final String tokenizerName;
    @Nonnull
    private final String defaultTokenizerName;

    Text(@Nullable String tokenizerName, @Nullable String defaultTokenizerName) {
        this.tokenizerName = tokenizerName;
        this.defaultTokenizerName = defaultTokenizerName == null ? DefaultTextTokenizer.NAME : defaultTokenizerName;
    }

    /**
     * Checks if the field contains a token. This token should either
     * be generated by the tokenizer associated with this text predicate or
     * should be a plausible token that the tokenizer could have generated. This
     * token will not be further sanitized or normalized before searching for it
     * in the text.
     *
     * @param token the token to search for
     * @return a new component for doing the actual evaluation
     */
    @Nonnull
    public QueryComponent contains(@Nonnull String token) {
        return getComponent(Comparisons.Type.TEXT_CONTAINS_ALL, Collections.singletonList(token));
    }

    /**
     * Checks if the field contains any token matching the provided prefix.
     * This should be the beginning of a token that could be generated by the
     * tokenizer associated with this text predicate. No additional sanitization
     * or normalization of this prefix will be performed before searching
     * for it in the text.
     *
     * @param prefix the prefix to search for
     * @return a new component for doing the actual evaluation
     */
    @Nonnull
    public QueryComponent containsPrefix(@Nonnull String prefix) {
        return getComponent(Comparisons.Type.TEXT_CONTAINS_PREFIX, Collections.singletonList(prefix));
    }

    /**
     * Checks if the field contains all of the provided tokens. At query
     * evaluation time, the tokens provided here will be tokenized into
     * a list of tokens. This predicate will then return {@link Boolean#TRUE}
     * if all of the tokens (except stop words) are present in the text field,
     * {@link Boolean#FALSE} if any of them are not, and <code>null</code> if
     * either the field is <code>null</code> or if the token list contains only
     * stop words or is empty. If the same token appears multiple times in the token
     * list, then the token must only appear at <i>least</i> once in the searched
     * text to satisfy the filter (i.e., it is <i>not</i> required to appear as many
     * times in the text as in the token list).
     *
     * @param tokens the tokens to search for
     * @return a new component for doing the actual evaluation
     */
    @Nonnull
    public QueryComponent containsAll(@Nonnull String tokens) {
        return getComponent(Comparisons.Type.TEXT_CONTAINS_ALL, tokens);
    }

    /**
     * Checks if the field contains all of provided tokens. This
     * behaves like {@link #containsAll(String)}, except that the token list
     * is assumed to have already been tokenized with an appropriate
     * tokenizer. No further sanitization or normalization is performed
     * on the tokens before searching for them in the text.
     *
     * @param tokens the tokens to search for
     * @return a new component for doing the actual evaluation
     */
    @Nonnull
    public QueryComponent containsAll(@Nonnull List<String> tokens) {
        return getComponent(Comparisons.Type.TEXT_CONTAINS_ALL, tokens);
    }

    /**
     * Checks if the field text contains all of the provided tokens within
     * a given number of tokens. For example, in the string "a b c" (tokenized
     * by whitespace), tokens "a" and "c" are a distance of two tokens of
     * each other, so <code>containsAll("a c", 2)</code> when evaluated
     * against that string would return {@link Boolean#TRUE}, but
     * <code>containsAll("a c", 1)</code> would return {@link Boolean#FALSE}.
     * Stop words in the query string are ignored, and if there are no
     * tokens in the string (or all tokens are stop words), this will
     * evaluate to <code>null</code>. It will also evaluate to <code>null</code>
     * if the field is <code>null</code>. If the same token appears multiple times
     * in the token list, then the token must only appear at <i>least</i> once in the searched
     * text to satisfy the filter (i.e., it is <i>not</i> required to appear as many
     * times in the text as in the token list).
     *
     * @param tokens the tokens to search for
     * @param maxDistance the maximum distance (expressed in number of tokens) to allow between found
     * @return a new component for doing the actual evaluation
     */
    @Nonnull
    public QueryComponent containsAll(@Nonnull String tokens, int maxDistance) {
        final Comparisons.Comparison comparison = new Comparisons.TextWithMaxDistanceComparison(tokens, maxDistance, tokenizerName, defaultTokenizerName);
        return getComponent(comparison);
    }

    /**
     * Checks if the field text contains all of the provided tokens within
     * a given number of tokens. This behaves like {@link #containsAll(String, int)}
     * except that the token list is assumed to have already been tokenized with
     * an appropriate tokenizer. No further sanitization or normalization is
     * performed on the tokens before searching for them in the text.
     *
     * @param tokens the tokens to search for
     * @param maxDistance the maximum distance (expressed in number of tokens) to allow between found
     * @return a new component for doing the actual evaluation
     */
    @Nonnull
    public QueryComponent containsAll(@Nonnull List<String> tokens, int maxDistance) {
        final Comparisons.Comparison comparison = new Comparisons.TextWithMaxDistanceComparison(tokens, maxDistance, tokenizerName, defaultTokenizerName);
        return getComponent(comparison);
    }

    /**
     * Checks if the field contains the given phrase. This will match
     * the given field if the given phrased (when tokenized) forms a
     * sublist of the original text. If the tokenization process removes
     * any stop words from the phrase, this will match documents that
     * contain any token in the place of the stop word. This will return
     * {@link Boolean#TRUE} if all of the tokens (except stop words)
     * can be found in the given document in the correct order,
     * {@link Boolean#FALSE} if any cannot, and <code>null</code> if the
     * phrase is empty or contains only stop words or if the field
     * itself is <code>null</code>.
     *
     * @param phrase the phrase to search for
     * @return a new component for doing the actual evaluation
     */
    @Nonnull
    public QueryComponent containsPhrase(@Nonnull String phrase) {
        return getComponent(Comparisons.Type.TEXT_CONTAINS_PHRASE, phrase);
    }

    /**
     * Checks if the field text contains the given phrase. This behaves like
     * {@link #containsPhrase(String)} except that the token list is assumed to
     * have already been tokenized with an appropriate tokenizer. No further
     * sanitization or normalization is performed on the tokens before searching
     * for them in the text. It is assumed that the order of the tokens in the
     * list is the same as the order of the tokens in the original phrase and
     * that there are no gaps (except as indicated by including the empty string to indicate
     * that there was a stop word in the original phrase).
     *
     * @param phraseTokens the tokens to search for in the order they appear in the phrase
     * @return a new component for doing the actual evaluation
     */
    @Nonnull
    public QueryComponent containsPhrase(@Nonnull List<String> phraseTokens) {
        return getComponent(Comparisons.Type.TEXT_CONTAINS_PHRASE, phraseTokens);
    }

    /**
     * Checks if the field contains any of the provided tokens. At query
     * evaluation time, the tokens provided here will be tokenized into
     * a list of tokens. This predicate will then return {@link Boolean#TRUE}
     * if any of the tokens (not counting stop words) are present,
     * {@link Boolean#FALSE} if all of them are not, and <code>null</code>
     * if either the field is <code>null</code> or if the token list contains
     * only stop words or is empty.
     *
     * @param tokens the tokens to search for
     * @return a new component for doing the actual evaluation
     */
    @Nonnull
    public QueryComponent containsAny(@Nonnull String tokens) {
        return getComponent(Comparisons.Type.TEXT_CONTAINS_ANY, tokens);
    }

    /**
     * Checks if the field contains all of provided tokens. This
     * behaves like {@link #containsAny(String)}, except that the token list
     * is assumed to have already been tokenized with an appropriate
     * tokenizer. No further sanitization or normalization is performed
     * on the tokens before searching for them in the text.
     *
     * @param tokens the tokens to search for
     * @return a new component for doing the actual evaluation
     */
    @Nonnull
    public QueryComponent containsAny(@Nonnull List<String> tokens) {
        return getComponent(Comparisons.Type.TEXT_CONTAINS_ANY, tokens);
    }

    @Nonnull
    private ComponentWithComparison getComponent(@Nonnull Comparisons.Type type, @Nonnull String tokens) {
        final Comparisons.Comparison comparison = new Comparisons.TextComparison(type, tokens, tokenizerName, defaultTokenizerName);
        return getComponent(comparison);
    }

    @Nonnull
    private ComponentWithComparison getComponent(@Nonnull Comparisons.Type type, @Nonnull List<String> tokens) {
        final Comparisons.Comparison comparison = new Comparisons.TextComparison(type, tokens, tokenizerName, defaultTokenizerName);
        return getComponent(comparison);
    }

    /**
     * Create a component that uses the underlying comparison. The comparison provided
     * is guaranteed to have its type be of some text type.
     *
     * @param comparison text comparison to use when creating the component
     * @return a component that uses <code>comparison</code> as its comparison
     */
    @Nonnull
    abstract ComponentWithComparison getComponent(@Nonnull Comparisons.Comparison comparison);
}
